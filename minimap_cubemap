import cv2
import numpy as np
from collections import deque

from Calibration import monitor_info

# pip install screeninfo

from cube_folder import cube_render
from shader_test import Perspective_Manager

import threading
# cube_render.asynchronous_create_window()

# Offset to lower everything in the mini-map
Y_OFFSET = 400

#important variables:
#big one is 7cm
#med is .048 Mcc
markerLength = 0.07 #meters

# Minimap resolution
MINIMAP_WIDTH = 720
MINIMAP_HEIGHT = 1080


# Monitor dimensions in meters (assuming 28 inches diagonal and 16:9 aspect ratio)
# MONITOR_WIDTH = 0.621
MONITOR_WIDTH, MONITOR_HEIGHT, dpi = monitor_info.get_monitor_dimensions()

# Scale factor for the mini-map
SCALE_X = MINIMAP_WIDTH / 2.0

monitor_width_scaled = MONITOR_WIDTH * SCALE_X


X_SCALING_FACTOR = 3  # Adjust this value to increase or decrease the side-to-side movement


# Define the size of the deque for smoothing
SMOOTHING_SIZE = 5
yaw_values = deque(maxlen=SMOOTHING_SIZE)
#shrink resolution?
shrink = False


# Camera resolution
cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)
WIDTH = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))  # Change this to your desired width
HEIGHT = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))  # Change this to your desired height
print(f"Detected webcam resolution: {WIDTH}x{HEIGHT}")

def draw_arrow(image, position, angle):
    length = 50
    end_x = int(position[0] + length * np.sin(angle))
    end_y = int(position[1] - length * np.cos(angle))
    cv2.arrowedLine(image, position, (end_x, end_y), (0, 0, 255), 2)

if shrink:
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    WIDTH = 640
    HEIGHT = 480


# cap.set(cv2.CAP_PROP_FRAME_WIDTH, WIDTH)
# cap.set(cv2.CAP_PROP_FRAME_HEIGHT, HEIGHT)


dictionary = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_6X6_250)


fx = fy = 1400  # This is a rough estimate and might need adjustment
cx = WIDTH / 2
cy = HEIGHT / 2

cameraMatrix = np.array([[fx, 0, cx], [0, fy, cy], [0, 0, 1]], dtype=np.float64)
distCoeffs = np.zeros((5,1), dtype=np.float64)
NAME = "Desktop_Webcam"
# cameraMatrix = np.load('Calibration/'+NAME+'camera_matrix.npy')
# distCoeffs = np.load('Calibration/'+NAME+'dist_coeffs.npy')



def draw_lines_to_monitor(image, arrow_tip, monitor_start, monitor_end, color):
    # Calculate the intersection points of the line from the arrow tip to the monitor sides with the edges of the minimap
    def intersection_with_edges(point1, point2, width, height):
        # Line equation: y = m*x + b
        if point2[0] - point1[0] == 0:  # Vertical line
            return [(point2[0], 0), (point2[0], height)]
        m = (point2[1] - point1[1]) / (point2[0] - point1[0])
        b = point1[1] - m * point1[0]
        
        # Calculate intersection with each edge
        top_intersection = (-b / m, 0)
        bottom_intersection = ((height - b) / m, height)
        left_intersection = (0, b)
        right_intersection = (width, m * width + b)
        
        # Return the two intersection points that are within the minimap boundaries
        intersections = [top_intersection, bottom_intersection, left_intersection, right_intersection]
        return [point for point in intersections if 0 <= point[0] <= width and 0 <= point[1] <= height]

    left_intersections = intersection_with_edges(arrow_tip, monitor_start, image.shape[1], image.shape[0])
    right_intersections = intersection_with_edges(arrow_tip, monitor_end, image.shape[1], image.shape[0])
    
    # Draw the lines
    cv2.line(image, arrow_tip, tuple(map(int, left_intersections[0])), color, 2)
    cv2.line(image, arrow_tip, tuple(map(int, right_intersections[0])), color, 2)

while True:
    ret, frame = cap.read()
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    corners, ids, rejectedImgPoints = cv2.aruco.detectMarkers(gray, dictionary)
    mirrored_frame = cv2.flip(frame, 1)  # Create a mirrored version for display


    mini_map = np.zeros((MINIMAP_HEIGHT, MINIMAP_WIDTH, 3), dtype=np.uint8)

    # Calculate the start and end points of the monitor line on the mini-map
    # Position the line at the top of the mini-map with the offset
    start_point = (int(MINIMAP_WIDTH/2 - monitor_width_scaled/2), 10 + Y_OFFSET)
    end_point = (int(MINIMAP_WIDTH/2 + monitor_width_scaled/2), 10 + Y_OFFSET)
    
    # Draw the monitor as a line on the mini-map
    cv2.line(mini_map, start_point, end_point, (255, 255, 255), 2)  # White line


    if len(corners) > 0:
        for corner in corners:
            corner[:, :, 0] = frame.shape[1] - corner[:, :, 0]
        
        mirrored_frame = cv2.aruco.drawDetectedMarkers(mirrored_frame, corners, ids)  # Draw on the mirrored frame

        # frame = cv2.aruco.drawDetectedMarkers(frame, corners, ids)
        rvecs, tvecs, _ = cv2.aruco.estimatePoseSingleMarkers(corners, markerLength, cameraMatrix, distCoeffs)

        # For simplicity, consider the first detected marker for the mini-map
        rvec = rvecs[0]
        tvec = tvecs[0]

        # Check and adjust the Z component of the rotation vector
        # print("Shape of rvec:", rvec.shape)
        # print("rvec:", rvec)

        # I THINK this is an offset for the monitor?? IDK I SHOULD REMOVE THIS...
        # if rvec[0][1] < 0:
        #     rvec[0][1] = -rvec[0][1]
        

        # Convert rotation vector to Euler angles for 2D rotation
        yaw = -cv2.Rodrigues(rvec)[0][2][0]
        # Inside the loop, after calculating the yaw:
        yaw_values.append(yaw)
        smoothed_yaw = sum(yaw_values) / len(yaw_values)

        # Calculate arrow's position on the minimap
        # position_x = int((MINIMAP_WIDTH/2 + tvec[0][0] * MINIMAP_WIDTH/2))  # Centered and scaled
        position_y = int(tvec[0][2] * MINIMAP_HEIGHT/2)

        position_x = int((MINIMAP_WIDTH/2 + tvec[0][0] * MINIMAP_WIDTH/2 * X_SCALING_FACTOR))  # Centered and scaled with the factor


        # Adjust x position based on distance to camera to account for the vision cone effect
        fov_adjustment = (1 - tvec[0][2]) * (MINIMAP_WIDTH/2 - position_x) * 0.5

        position_x += int(fov_adjustment)

        position = (position_x, position_y + Y_OFFSET)

                


        # Draw the lines from the arrow tip to the monitor sides
        line_color = (255, 0, 0)  # Blue
        arrow_tip = (int(position[0] + 50 * np.sin(smoothed_yaw)), int(position[1] - 50 * np.cos(smoothed_yaw)))
        draw_lines_to_monitor(mini_map, arrow_tip, start_point, end_point, line_color)
 


        draw_arrow(mini_map, position, smoothed_yaw)
        # print(tvec[0][0])
        # cube_render.update_perspective(
        Perspective_Manager.update(-tvec[0][0], tvec[0][1], tvec[0][2])
        # Draw the rotation vectors on the frame
        for i in range(len(rvecs)):
            mirrored_frame = cv2.drawFrameAxes(mirrored_frame, cameraMatrix, distCoeffs, rvecs[i], tvecs[i], 0.03)
            
            # Calculate the distance from the camera to the marker
            distance = np.linalg.norm(tvecs[i])
            
            # Define text properties
            text = f"Distance: {distance:.2f}m"
            font_scale = 0.5
            font_thickness = 1
            font_color = (0, 0, 255)  # RED
            bg_color = (0, 0, 0)  # BLACK
            font = cv2.FONT_HERSHEY_SIMPLEX
            
            # Calculate text size
            (text_width, text_height), _ = cv2.getTextSize(text, font, font_scale, font_thickness)
            
            # Define text and background rectangle positions
            text_offset_x = int(corners[i][0][0][0])
            text_offset_y = int(corners[i][0][0][1])
            box_coords = ((text_offset_x, text_offset_y + 5), (text_offset_x + text_width, text_offset_y - text_height - 5))
            
            # Draw a black background rectangle
            cv2.rectangle(mirrored_frame, box_coords[0], box_coords[1], bg_color, cv2.FILLED)
            
            # Display the distance on the frame
            cv2.putText(mirrored_frame, text, (text_offset_x, text_offset_y), font, font_scale, font_color, font_thickness, lineType=cv2.LINE_AA)

    
    cv2.imshow('Frame', mirrored_frame)
    cv2.imshow('Mini-Map', mini_map)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break



cap.release()
cv2.destroyAllWindows()
